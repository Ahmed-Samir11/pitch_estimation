{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions to get the output length of a conv1d layer.\n",
    "from functools import reduce\n",
    "def get_conv1d_len_func(model):\n",
    "    return lambda i: torch.floor((i + 2 * model.padding[0] - model.dilation[0] * (model.kernel_size[0] - 1) - 1) / model.stride[0] + 1)\n",
    "        \n",
    "def get_transpose_conv1d_len_func(model):\n",
    "    return lambda i: (i - 1) * model.stride[0] - 2 * model.padding[0] + model.dilation[0] * (model.kernel_size[0] - 1) + model.output_padding[0] + 1\n",
    "\n",
    "def get_unfold_len(length, window_ks, window_stride):\n",
    "    return (length - window_ks) // window_stride + 1\n",
    "\n",
    "# A simple conv + batch norm + relu model. \n",
    "# Note that the padding is set to 0.\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_ins, num_outs, kernel_size=3,stride=1, dilation=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Note that the padding is 0 here. \n",
    "        self.conv = nn.Conv1d(num_ins, num_outs, kernel_size, padding=0, stride=stride,dilation=dilation)\n",
    "        self.bn = nn.BatchNorm1d(num_outs) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        return x\n",
    "    \n",
    "    # This helps you judge the output length of the model given some input length. \n",
    "    def get_output_lengths(self, length):\n",
    "        return self.len_funcs(length)\n",
    "\n",
    "# A more complex CNN blosk with residual path. aka ResBlock.\n",
    "# You can chain several Resblock or Block together. \n",
    "class ResBlock(nn.Module):\n",
    "    '''\n",
    "    Gaddy and Klein, 2021, https://arxiv.org/pdf/2106.01933.pdf \n",
    "    Original code:\n",
    "        https://github.com/dgaddy/silent_speech/blob/master/transformer.py\n",
    "    '''\n",
    "    def __init__(self, num_ins, num_outs, kernel_size = 3, padding = 1, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_ins, num_outs, kernel_size, padding=padding, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(num_outs)\n",
    "        self.conv2 = nn.Conv1d(num_outs, num_outs, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(num_outs)\n",
    "\n",
    "        # This helps whenever in_channels != out_channels or stride != 1.\n",
    "        # E.g. the first input Resblock layer, or you want to downsample the input.\n",
    "        if stride != 1 or num_ins != num_outs:\n",
    "            # With kernel size of 1, this is essentially a linear layer but with stride. \n",
    "            self.residual_path = nn.Conv1d(num_ins, num_outs, 1, stride=stride)\n",
    "            self.res_norm = nn.BatchNorm1d(num_outs)\n",
    "        else:\n",
    "            self.residual_path = None\n",
    "        \n",
    "        # This helps you judge the output length of the model given some input length.\n",
    "        # len_funcs is a list of functions that takes in a length and returns the output length.\n",
    "        len_funcs = []\n",
    "        len_funcs.append(get_conv1d_len_func(self.conv1))\n",
    "        len_funcs.append(get_conv1d_len_func(self.conv2))\n",
    "        self.len_funcs = len_funcs\n",
    "        \n",
    "        \n",
    "        # Helps you run a sanity check that if the residual path is activated, \n",
    "        # it should be configured such that the output length is the same as the output length of the main path.\n",
    "        if self.residual_path is not None:\n",
    "            residual_len_funcs = get_conv1d_len_func(self.residual_path)\n",
    "            for data_length in torch.arange(10, 100, 1):\n",
    "                main_len = reduce(lambda x, func: func(x), self.len_funcs, data_length).int()\n",
    "                res_len = residual_len_funcs(data_length)\n",
    "                assert main_len == res_len, f\"Residual path length {res_len} is not the same as the main path length {main_len}. Please check the configuration or reach out to me.\"\n",
    "    \n",
    "    def get_output_lengths(self, length):\n",
    "        return reduce(lambda x, func: func(x), self.len_funcs, length).int()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_value = x\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        if self.residual_path is not None:\n",
    "            res = self.res_norm(self.residual_path(input_value))\n",
    "        else:\n",
    "            res = input_value\n",
    "\n",
    "        return F.relu(x + res)\n",
    "    \n",
    "# An example of CNN that chains several ResBlocks together.\n",
    "# Generally, this is more powerful than the simple Block model, but is also more prune to overfitting.\n",
    "# Original conv blocks: no dropout, 2 hidden-hidden blocks.\n",
    "class Original(nn.Module):\n",
    "    def __init__(self, in_channels=8, hidden_dim = 1024):\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ResBlock(in_channels, hidden_dim, kernel_size = 3, stride = 1),\n",
    "            ResBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1),\n",
    "            ResBlock(hidden_dim, hidden_dim, kernel_size=3, stride=1),\n",
    "        )\n",
    "\n",
    "        def get_model_len_func(model):\n",
    "            len_funcs = []\n",
    "            for i in model.conv_blocks:\n",
    "                for j in range(2):\n",
    "                    len_funcs.append(get_conv1d_len_func(eval(\"i.conv\" + str(j + 1))))\n",
    "            return len_funcs\n",
    "\n",
    "        self.len_funcs = get_model_len_func(self)\n",
    "\n",
    "    def get_output_lengths(self, length):\n",
    "        return reduce(lambda x, func: func(x), self.len_funcs, length)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: shape (batchsize, num_in_feats, seq_len).\n",
    "        \n",
    "        Return:\n",
    "            out: shape (batchsize, num_out_feats, seq_len).\n",
    "        \"\"\"\n",
    "        return self.conv_blocks(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stay consistent with Pytorch API, typically the input to a CNN has the shape (B, C, T)\n",
    "# (B: batch size, C: number of channels, T: sequence length).\n",
    "\n",
    "# You need to make sure that the \"in_channel\" (i.e. the number of channels in the first convolution layer) \n",
    "# or \"num_in\" as I used above\n",
    "# is EXACTLY the same as the number of channels in the input.\n",
    "\n",
    "# Here's one example.\n",
    "# This model expects the input to have 8 channels, and the output will have 1024 channels.\n",
    "model = Original(in_channels=8, hidden_dim=1024)\n",
    "\n",
    "# Let's say the input has a length of 100.\n",
    "# Create some dummy input with 8 channels. \n",
    "# The first dimension is the batch dimension.\n",
    "data = torch.rand((1, 8, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024, 100])\n"
     ]
    }
   ],
   "source": [
    "# Forward pass.\n",
    "# As you can see, the model doesn't change the shape of the input after forward pass.\n",
    "with torch.no_grad():\n",
    "    print(model(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sometimes the output length of a CNN can be troublesome.\n",
    "# You can use the get_output_lengths to get the output length of the model.\n",
    "# As you can see, regradless of the input length, the output length is always the same.\n",
    "# We can safely use this 'Original' model as a feature extractor without worrying about change in length. \n",
    "for data_length in torch.arange(10, 100, 1):\n",
    "    assert model.get_output_lengths(data_length) == data_length, f\"Error: {model.get_output_lengths(data_length)}\"\n",
    "    print(f\"Input length: {data_length}, Output length: {model.get_output_lengths(data_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the CNN encoder above, we can easily build any classifiers.\n",
    "# Change num_classes to the number of classes you have.\n",
    "# Here's one example of CNN + BiLSTM + Linear classifier.\n",
    "class CNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, in_channels=8, hidden_dim = 1024, num_classes=10, num_lstm_layers=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cnn = Original(in_channels=in_channels, hidden_dim=hidden_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: shape (batchsize, num_in_feats, seq_len).\n",
    "        \n",
    "        Return:\n",
    "            out: shape (batchsize, num_classes).\n",
    "        \"\"\"\n",
    "        # (B, C, T)\n",
    "        x = self.cnn(x)\n",
    "        \n",
    "        # Before passing into the LSTM, change the shape to (B, T, C).\n",
    "        x, _ = self.lstm(x.permute(0, 2, 1))\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')\n",
    "model = CNN_LSTM_Classifier(in_channels=8, hidden_dim=1024, num_classes=10, num_lstm_layers=2).to(device)\n",
    "data = torch.rand((1, 8, 100)).to(device)\n",
    "with torch.no_grad():\n",
    "    print(model(data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
