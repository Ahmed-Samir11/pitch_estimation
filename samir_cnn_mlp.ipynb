{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/blastaistudent/.local/lib/python3.11/site-packages (4.66.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchinfo in /home/blastaistudent/.local/lib/python3.11/site-packages (1.8.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torchcrepe in /home/blastaistudent/.local/lib/python3.11/site-packages (0.0.23)\n",
      "Requirement already satisfied: librosa>=0.9.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (0.10.2.post1)\n",
      "Requirement already satisfied: resampy in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (0.4.3)\n",
      "Requirement already satisfied: scipy in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (1.14.0)\n",
      "Requirement already satisfied: torch in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (2.4.0)\n",
      "Requirement already satisfied: torchaudio in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /home/blastaistudent/.local/lib/python3.11/site-packages (from torchcrepe) (4.66.5)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (3.0.1)\n",
      "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (2.0.1)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (1.5.1)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (0.60.0)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (0.12.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (0.4.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (4.12.2)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from librosa>=0.9.1->torchcrepe) (1.0.8)\n",
      "Requirement already satisfied: filelock in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (3.15.4)\n",
      "Requirement already satisfied: sympy in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (1.13.1)\n",
      "Requirement already satisfied: networkx in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from torch->torchcrepe) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/blastaistudent/.local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchcrepe) (12.6.20)\n",
      "Requirement already satisfied: packaging in /home/blastaistudent/.local/lib/python3.11/site-packages (from lazy-loader>=0.1->librosa>=0.9.1->torchcrepe) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from numba>=0.51.0->librosa>=0.9.1->torchcrepe) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.9.1->torchcrepe) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from pooch>=1.1->librosa>=0.9.1->torchcrepe) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from scikit-learn>=0.20.0->librosa>=0.9.1->torchcrepe) (3.5.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from soundfile>=0.12.1->librosa>=0.9.1->torchcrepe) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from jinja2->torch->torchcrepe) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/blastaistudent/.local/lib/python3.11/site-packages (from sympy->torch->torchcrepe) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /home/blastaistudent/.local/lib/python3.11/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa>=0.9.1->torchcrepe) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/blastaistudent/.local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->torchcrepe) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/blastaistudent/.local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->torchcrepe) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/blastaistudent/.local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->torchcrepe) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/blastaistudent/.local/lib/python3.11/site-packages (from requests>=2.19.0->pooch>=1.1->librosa>=0.9.1->torchcrepe) (2024.7.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tqdm\n",
    "%pip install torchinfo\n",
    "%pip install torchcrepe\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "from pickle import dump\n",
    "import torchcrepe\n",
    "import scipy\n",
    "import random\n",
    "from utils import *\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "#from cloudpickle import dump\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some helper functions to get the output length of a conv1d layer.\n",
    "from functools import reduce\n",
    "def get_conv1d_len_func(model):\n",
    "    return lambda i: torch.floor((i + 2 * model.padding[0] - model.dilation[0] * (model.kernel_size[0] - 1) - 1) / model.stride[0] + 1)\n",
    "        \n",
    "def get_transpose_conv1d_len_func(model):\n",
    "    return lambda i: (i - 1) * model.stride[0] - 2 * model.padding[0] + model.dilation[0] * (model.kernel_size[0] - 1) + model.output_padding[0] + 1\n",
    "\n",
    "def get_unfold_len(length, window_ks, window_stride):\n",
    "    return (length - window_ks) // window_stride + 1\n",
    "\n",
    "# A simple conv + batch norm + relu model. \n",
    "# Note that the padding is set to 0.\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, num_ins, num_outs, kernel_size=3,stride=1, dilation=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Note that the padding is 0 here. \n",
    "        self.conv = nn.Conv1d(num_ins, num_outs, kernel_size, padding=0, stride=stride,dilation=dilation)\n",
    "        self.bn = nn.BatchNorm1d(num_outs) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn(self.conv(x)))\n",
    "        return x\n",
    "    \n",
    "    # This helps you judge the output length of the model given some input length. \n",
    "    def get_output_lengths(self, length):\n",
    "        return self.len_funcs(length)\n",
    "\n",
    "# A more complex CNN blosk with residual path. aka ResBlock.\n",
    "# You can chain several Resblock or Block together. \n",
    "class ResBlock(nn.Module):\n",
    "    '''\n",
    "    Gaddy and Klein, 2021, https://arxiv.org/pdf/2106.01933.pdf \n",
    "    Original code:\n",
    "        https://github.com/dgaddy/silent_speech/blob/master/transformer.py\n",
    "    '''\n",
    "    def __init__(self, num_ins, num_outs, kernel_size = 3, padding = 1, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(num_ins, num_outs, kernel_size, padding=padding, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm1d(num_outs)\n",
    "        self.conv2 = nn.Conv1d(num_outs, num_outs, kernel_size, padding=padding)\n",
    "        self.bn2 = nn.BatchNorm1d(num_outs)\n",
    "\n",
    "        # This helps whenever in_channels != out_channels or stride != 1.\n",
    "        # E.g. the first input Resblock layer, or you want to downsample the input.\n",
    "        if stride != 1 or num_ins != num_outs:\n",
    "            # With kernel size of 1, this is essentially a linear layer but with stride. \n",
    "            self.residual_path = nn.Conv1d(num_ins, num_outs, 1, stride=stride)\n",
    "            self.res_norm = nn.BatchNorm1d(num_outs)\n",
    "        else:\n",
    "            self.residual_path = None\n",
    "        \n",
    "        # This helps you judge the output length of the model given some input length.\n",
    "        # len_funcs is a list of functions that takes in a length and returns the output length.\n",
    "        len_funcs = []\n",
    "        len_funcs.append(get_conv1d_len_func(self.conv1))\n",
    "        len_funcs.append(get_conv1d_len_func(self.conv2))\n",
    "        self.len_funcs = len_funcs\n",
    "        \n",
    "        \n",
    "        # Helps you run a sanity check that if the residual path is activated, \n",
    "        # it should be configured such that the output length is the same as the output length of the main path.\n",
    "        if self.residual_path is not None:\n",
    "            residual_len_funcs = get_conv1d_len_func(self.residual_path)\n",
    "            for data_length in torch.arange(10, 100, 1):\n",
    "                main_len = reduce(lambda x, func: func(x), self.len_funcs, data_length).int()\n",
    "                res_len = residual_len_funcs(data_length)\n",
    "                assert main_len == res_len, f\"Residual path length {res_len} is not the same as the main path length {main_len}. Please check the configuration or reach out to me.\"\n",
    "    \n",
    "    def get_output_lengths(self, length):\n",
    "        return reduce(lambda x, func: func(x), self.len_funcs, length).int()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        input_value = x\n",
    "\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.bn2(self.conv2(x))\n",
    "\n",
    "        if self.residual_path is not None:\n",
    "            res = self.res_norm(self.residual_path(input_value))\n",
    "        else:\n",
    "            res = input_value\n",
    "\n",
    "        return F.relu(x + res)\n",
    "    \n",
    "# An example of CNN that chains several ResBlocks together.\n",
    "# Generally, this is more powerful than the simple Block model, but is also more prune to overfitting.\n",
    "# Original conv blocks: no dropout, 2 hidden-hidden blocks.\n",
    "class Original(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim):\n",
    "        super().__init__()\n",
    "\n",
    "    \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ResBlock(in_channels, hidden_dim, kernel_size = 3, stride = 1),\n",
    "            ResBlock(hidden_dim, hidden_dim, kernel_size = 3, stride = 1),\n",
    "            ResBlock(hidden_dim, hidden_dim, kernel_size=3, stride=1),\n",
    "        )\n",
    "\n",
    "        def get_model_len_func(model):\n",
    "            len_funcs = []\n",
    "            for i in model.conv_blocks:\n",
    "                for j in range(2):\n",
    "                    len_funcs.append(get_conv1d_len_func(eval(\"i.conv\" + str(j + 1))))\n",
    "            return len_funcs\n",
    "\n",
    "        self.len_funcs = get_model_len_func(self)\n",
    "\n",
    "    def get_output_lengths(self, length):\n",
    "        return reduce(lambda x, func: func(x), self.len_funcs, length)\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: shape (batchsize, num_in_feats, seq_len).\n",
    "        \n",
    "        Return:\n",
    "            out: shape (batchsize, num_out_feats, seq_len).\n",
    "        \"\"\"\n",
    "        return self.conv_blocks(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(dir):\n",
    "    if not os.path.exists(dir):\n",
    "        os.mkdir(dir)\n",
    "\n",
    "def save_pkl(obj, save_path):\n",
    "    \"\"\"Save a Pyleecan object in a pkl file using cloudpickle\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    obj: Pyleecan object\n",
    "        object to save\n",
    "    save_path: str\n",
    "        file path\n",
    "    \"\"\"\n",
    "\n",
    "    with open(save_path, \"wb\") as save_file:\n",
    "        dump(obj, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: copy this block for MIR 1k dataset and dataloader. \n",
    "# Create a pytorch dataset for MIR 1k.\n",
    "\n",
    "\n",
    "CENTS_PER_BIN = 20  # cents\n",
    "MAX_FMAX = 2006.  # hz\n",
    "PITCH_BINS = 360\n",
    "SAMPLE_RATE = 16000  # hz\n",
    "WINDOW_SIZE = 1024\n",
    "\n",
    "def frequency_to_cents(frequency):\n",
    "    \"\"\"Convert frequency in Hz to cents\"\"\"\n",
    "    return 1200 * torch.log2(frequency / 10.)\n",
    "\n",
    "# We can use this function to quantize the pitch to the nearest bin.\n",
    "# but 1997 actually corresponds to 31.7hz instead of 32.7 as noted in the paper. \n",
    "def cents_to_bins(cents, quantize_fn=torch.floor):\n",
    "    \"\"\"Converts cents to pitch bins\"\"\"\n",
    "    bins = (cents - 1997.3794084376191) / CENTS_PER_BIN\n",
    "    return quantize_fn(bins).int()\n",
    "\n",
    "def frequency_to_bins(frequency, quantize_fn=torch.floor):\n",
    "    \"\"\"Convert frequency in Hz to pitch bins\"\"\"\n",
    "    mask = torch.isclose(frequency, torch.tensor([0.0], dtype = torch.float32))\n",
    "    result = cents_to_bins(frequency_to_cents(frequency), quantize_fn)\n",
    "    \n",
    "    # Pitch label: 0 - 359 \n",
    "    # 360: unvoiced.\n",
    "    # Total of 361 bins.\n",
    "    result[mask] = 360\n",
    "    return result \n",
    "\n",
    "\n",
    "class MIR1kDataset(Dataset):\n",
    "    def __init__(self, mel_dir, pitch_dir, fids):\n",
    "        self.mel_dir = mel_dir\n",
    "        self.pitch_dir = pitch_dir\n",
    "        \n",
    "        # File ids.\n",
    "        fids = read(fids).strip().split('\\n')\n",
    "        \n",
    "        # Check if all features files exist. \n",
    "        self.fids = fids\n",
    "        for i in fids:\n",
    "            assert os.path.exists(os.path.join(mel_dir, f\"{i}.npy\"))\n",
    "            assert os.path.exists(os.path.join(pitch_dir, f\"{i}.npy\"))\n",
    "    def __len__(self):\n",
    "        return len(self.fids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        fid = self.fids[idx]\n",
    "        mel = np.load(os.path.join(self.mel_dir, f\"{fid}.npy\"))\n",
    "        pitch = np.load(os.path.join(self.pitch_dir, f\"{fid}.npy\"))\n",
    "        return mel, pitch\n",
    "\n",
    "# Create a collate fn that randomly crop the waveform and pitch.\n",
    "# min_len: 1 sec of mel. max_len: 3sec of mel.\n",
    "def collate_fn(batch, min_len = 50, max_len = 150):\n",
    "    mel = [i[0] for i in batch]\n",
    "    pitch = [i[1] for i in batch]\n",
    "    \n",
    "    # Randomly crop the mel and pitch.\n",
    "    crop_len = random.randint(min_len, max_len)\n",
    "    min_mel_len = min([i.shape[1] for i in mel])\n",
    "    \n",
    "    random_start = random.randint(0, min_mel_len - crop_len)\n",
    "    \n",
    "    # (B, C, crop_len)\n",
    "    mel = torch.stack([torch.tensor(i[:, random_start:random_start + crop_len]) for i in mel]).float()\n",
    "    \n",
    "    # (B, crop_len)\n",
    "    pitch = torch.stack([torch.tensor(i[random_start:random_start + crop_len]) for i in pitch]).float()\n",
    "    orig_pitch = pitch.clone()\n",
    "    \n",
    "    # Convert pitch to cents.\n",
    "    pitch = frequency_to_bins(pitch)\n",
    "    return mel, pitch, orig_pitch\n",
    "\n",
    "# Train dataset and dataloader.\n",
    "train_dataset = MIR1kDataset(mel_dir='/data/pitch_estimation/dataset/MIR-1K/mel_spec_both', \n",
    "                             pitch_dir='/data/pitch_estimation/dataset/MIR-1K/pitch_50', \n",
    "                             fids='/data/pitch_estimation/dataset/MIR-1K/train.txt')\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "\n",
    "# Val dataset and dataloader.\n",
    "val_dataset = MIR1kDataset(mel_dir='/data/pitch_estimation/dataset/MIR-1K/mel_spec_both',\n",
    "                           pitch_dir='/data/pitch_estimation/dataset/MIR-1K/pitch_50',\n",
    "                           fids='/data/pitch_estimation/dataset/MIR-1K/val.txt')\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Test dataset and dataloader.\n",
    "test_dataset = MIR1kDataset(mel_dir='/data/pitch_estimation/dataset/MIR-1K/mel_spec_both',\n",
    "                            pitch_dir='/data/pitch_estimation/dataset/MIR-1K/pitch_50',\n",
    "                            fids='/data/pitch_estimation/dataset/MIR-1K/test.txt')\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CREPE_ResNet_Model(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim, num_bins=361, dropout_prob=0.5):\n",
    "        super(CREPE_ResNet_Model, self).__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ResBlock(in_channels, 64, kernel_size=5, stride=1, padding=2),\n",
    "            ResBlock(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            ResBlock(128, 256, kernel_size=5, stride=1, padding=2),\n",
    "            ResBlock(256, 512, kernel_size=5, stride=1, padding=2),\n",
    "            ResBlock(512, hidden_dim, kernel_size=5, stride=1, padding=2),\n",
    "        )\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_prob),\n",
    "            nn.Linear(256, num_bins)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)  # Pass through the ResBlocks\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, sequence_length, hidden_dim)\n",
    "        \n",
    "        batch_size, seq_length, hidden_dim = x.size()\n",
    "        x = x.reshape(-1, hidden_dim)  # Flatten to (batch_size * sequence_length, hidden_dim)\n",
    "        x = self.mlp(x)  # Pass through MLP\n",
    "        \n",
    "        x = x.reshape(batch_size, seq_length, -1)  # Reshape back to (batch_size, seq_length, num_bins)\n",
    "        x = x.permute(0, 2, 1)  # Permute back to (batch_size, num_bins, sequence_length)\n",
    "        return x  # Final output shape: (batch_size, num_bins, sequence_length)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels = 256, hidden_dim = 512, num_bins=361, dropout_prob=0.25):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            ResBlock(in_channels, hidden_dim),\n",
    "            ResBlock(hidden_dim, 512),\n",
    "            ResBlock(512, 256),\n",
    "            ResBlock(256, 128),\n",
    "            ResBlock(128, 64),\n",
    "            ResBlock(64, num_bins),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_blocks(x)  # Pass through the ResBlocks\n",
    "        x = x.permute(0, 2, 1)  # Permute to (batch_size, sequence_length, hidden_dim)\n",
    "        \n",
    "        batch_size, seq_length, hidden_dim = x.size()\n",
    "        x = x.reshape(-1, hidden_dim)  # Flatten to (batch_size * sequence_length, hidden_dim)\n",
    "        #x = self.mlp(x)  # Pass through MLP\n",
    "        \n",
    "        x = x.reshape(batch_size, seq_length, -1)  # Reshape back to (batch_size, seq_length, num_bins)\n",
    "        x = x.permute(0, 2, 1)  # Permute back to (batch_size, num_bins, sequence_length)\n",
    "        return x   # Final output shape should be (batch_size, num_bins, sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CREPE_ResNet_Model                       --\n",
      "├─Sequential: 1-1                        --\n",
      "│    └─ResBlock: 2-1                     --\n",
      "│    │    └─Conv1d: 3-1                  81,984\n",
      "│    │    └─BatchNorm1d: 3-2             128\n",
      "│    │    └─Conv1d: 3-3                  20,544\n",
      "│    │    └─BatchNorm1d: 3-4             128\n",
      "│    │    └─Conv1d: 3-5                  16,448\n",
      "│    │    └─BatchNorm1d: 3-6             128\n",
      "│    └─ResBlock: 2-2                     --\n",
      "│    │    └─Conv1d: 3-7                  41,088\n",
      "│    │    └─BatchNorm1d: 3-8             256\n",
      "│    │    └─Conv1d: 3-9                  82,048\n",
      "│    │    └─BatchNorm1d: 3-10            256\n",
      "│    │    └─Conv1d: 3-11                 8,320\n",
      "│    │    └─BatchNorm1d: 3-12            256\n",
      "│    └─ResBlock: 2-3                     --\n",
      "│    │    └─Conv1d: 3-13                 164,096\n",
      "│    │    └─BatchNorm1d: 3-14            512\n",
      "│    │    └─Conv1d: 3-15                 327,936\n",
      "│    │    └─BatchNorm1d: 3-16            512\n",
      "│    │    └─Conv1d: 3-17                 33,024\n",
      "│    │    └─BatchNorm1d: 3-18            512\n",
      "│    └─ResBlock: 2-4                     --\n",
      "│    │    └─Conv1d: 3-19                 655,872\n",
      "│    │    └─BatchNorm1d: 3-20            1,024\n",
      "│    │    └─Conv1d: 3-21                 1,311,232\n",
      "│    │    └─BatchNorm1d: 3-22            1,024\n",
      "│    │    └─Conv1d: 3-23                 131,584\n",
      "│    │    └─BatchNorm1d: 3-24            1,024\n",
      "│    └─ResBlock: 2-5                     --\n",
      "│    │    └─Conv1d: 3-25                 2,622,464\n",
      "│    │    └─BatchNorm1d: 3-26            2,048\n",
      "│    │    └─Conv1d: 3-27                 5,243,904\n",
      "│    │    └─BatchNorm1d: 3-28            2,048\n",
      "│    │    └─Conv1d: 3-29                 525,312\n",
      "│    │    └─BatchNorm1d: 3-30            2,048\n",
      "├─Sequential: 1-2                        --\n",
      "│    └─Linear: 2-6                       524,800\n",
      "│    └─ReLU: 2-7                         --\n",
      "│    └─Dropout: 2-8                      --\n",
      "│    └─Linear: 2-9                       131,328\n",
      "│    └─ReLU: 2-10                        --\n",
      "│    └─Dropout: 2-11                     --\n",
      "│    └─Linear: 2-12                      92,777\n",
      "=================================================================\n",
      "Total params: 12,026,665\n",
      "Trainable params: 12,026,665\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = CREPE_ResNet_Model(in_channels=256, hidden_dim = 1024)\n",
    "print(summary(model))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs, num_eval_epoch, patience,\n",
    "                criterion=None, optimizer=None, scheduler=None, save_dir=\"\", gpu_number=6):\n",
    "    mkdir(save_dir)\n",
    "    \n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    device = torch.device(f'cuda:{gpu_number}' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for _, (inputs, labels, _)  in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "            #print(f\"inputs:{inputs}\")\n",
    "            #print(f\"labels: {labels}\")\n",
    "            inputs = torch.tensor(inputs, dtype = torch.float)\n",
    "            inputs = inputs.to(device)\n",
    "            #labels = torch.tensor(labels)\n",
    "            labels = labels.to(device).long()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        train_loss_epoch = running_loss / len(train_loader)\n",
    "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss_epoch}')\n",
    "        train_loss.append(train_loss_epoch)\n",
    "        \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "        \n",
    "        if (epoch + 1) % num_eval_epoch == 0:\n",
    "            result = evaluate_model(model, val_loader, criterion, device)\n",
    "            print(f'Epoch: {epoch} Validation Loss: {result[\"val_loss\"]}, Validation Accuracy: {result[\"val_acc\"]}')\n",
    "            val_loss.append(result[\"val_loss\"])\n",
    "            val_acc.append(result[\"val_acc\"])\n",
    "            \n",
    "            if result[\"val_loss\"] < best_val_loss:\n",
    "                best_val_loss = result[\"val_loss\"]\n",
    "                torch.save({'model_ckpt': model.state_dict(),\n",
    "                            \"optimizer\": optimizer.state_dict(),\n",
    "                            \"epoch\": epoch,\n",
    "                            \"best_val_loss\": best_val_loss,\n",
    "                            }, os.path.join(save_dir, 'best_val_ckpt.pth'))\n",
    "                print(f\"Best model saved at epoch {epoch}, val loss: {best_val_loss}\")\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"No improvement in validation loss for {patience_counter} consecutive evaluations.\")\n",
    "            \n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    stats = {'train_loss': train_loss, 'val_loss': val_loss, 'val_acc': val_acc}\n",
    "    save_pkl(stats, os.path.join(save_dir, 'stats.pkl'))\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        for _, (inputs, labels, _) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            inputs = torch.tensor(inputs, dtype = torch.float)\n",
    "            inputs = inputs.to(device)\n",
    "            #labels = torch.tensor(labels)\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            val_loss += criterion(outputs, labels).item()\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy =  correct / total\n",
    "    val_loss /= len(dataloader)\n",
    "    return {'val_loss': val_loss, 'val_acc': accuracy}\n",
    "\n",
    "\n",
    "def test_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, (inputs, labels, _) in tqdm(enumerate(dataloader), total=len(dataloader)):\n",
    "            inputs = torch.tensor(inputs, dtype = torch.float)\n",
    "            inputs = inputs.to(device)\n",
    "            #labels = torch.tensor(labels)\n",
    "            labels = labels.to(device).long()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/tmp/ipykernel_2019828/3361870488.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype = torch.float)\n",
      " 15%|█▍        | 8/54 [00:00<00:01, 33.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Loss: 4.225996211723045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150, Loss: 2.6089278724458485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 35.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/150, Loss: 2.155066384209527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/150, Loss: 1.975778720996998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/150, Loss: 1.8287992080052693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/150, Loss: 1.7050888096844707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 35.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/150, Loss: 1.6773735108198944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/150, Loss: 1.6689927379290264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/150, Loss: 1.647288775002515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/150, Loss: 1.6435350025141682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/tmp/ipykernel_2019828/3361870488.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype = torch.float)\n",
      "100%|██████████| 4/4 [00:00<00:00, 64.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 Validation Loss: 1.4117673635482788, Validation Accuracy: 63.2\n",
      "Best model saved at epoch 9, val loss: 1.4117673635482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 35.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/150, Loss: 1.617627101915854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/150, Loss: 1.6104532502315663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 35.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/150, Loss: 1.6389148434003193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/150, Loss: 1.6056412701253537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/150, Loss: 1.6217947513968856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/150, Loss: 1.6058288017908733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/150, Loss: 1.6148053738805983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/150, Loss: 1.6064375793492351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/150, Loss: 1.6037602821985881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 35.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/150, Loss: 1.6333535291530468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 86.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 Validation Loss: 1.5873027443885803, Validation Accuracy: 46.5\n",
      "No improvement in validation loss for 1 consecutive evaluations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/150, Loss: 1.6005880015867728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/150, Loss: 1.5955284591074343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/150, Loss: 1.6077108140344973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/150, Loss: 1.6422210600641038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 34.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/150, Loss: 1.5799416414013616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 33.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/150, Loss: 1.6114070327193648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/150, Loss: 1.6047050069879603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/150, Loss: 1.579202980906875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/150, Loss: 1.620387092784599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/150, Loss: 1.5961303490179557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 60.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 Validation Loss: 1.3205126225948334, Validation Accuracy: 69.98\n",
      "Best model saved at epoch 29, val loss: 1.3205126225948334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 27.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/150, Loss: 1.6078079055856775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/150, Loss: 1.6214459030716508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/150, Loss: 1.6128426922692194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/150, Loss: 1.6107340852419536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/150, Loss: 1.6235127912627325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/150, Loss: 1.6159026975984927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/150, Loss: 1.6409323745303683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/150, Loss: 1.6324332930423595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/150, Loss: 1.6109015433876603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/150, Loss: 1.6469728416866727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 62.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 Validation Loss: 1.3477917611598969, Validation Accuracy: 67.44\n",
      "No improvement in validation loss for 2 consecutive evaluations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/150, Loss: 1.625124829786795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/150, Loss: 1.63656304942237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/150, Loss: 1.6168052355448406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/150, Loss: 1.596388041973114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/150, Loss: 1.6345467766125996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/150, Loss: 1.6105043093363445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/150, Loss: 1.5949187411202326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/150, Loss: 1.6060739623175726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150, Loss: 1.5937906746511106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150, Loss: 1.6149051608862701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 67.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 Validation Loss: 1.3187527060508728, Validation Accuracy: 49.74\n",
      "Best model saved at epoch 49, val loss: 1.3187527060508728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/150, Loss: 1.6210478632538408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/150, Loss: 1.6129687936217696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/150, Loss: 1.5887055330806308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/150, Loss: 1.6108477490919608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/150, Loss: 1.6206931626355205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/150, Loss: 1.636325423364286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150, Loss: 1.5809076141428064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/150, Loss: 1.6284739220583881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150, Loss: 1.6287124752998352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/150, Loss: 1.609823015001085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 60.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59 Validation Loss: 1.4062286615371704, Validation Accuracy: 67.16\n",
      "No improvement in validation loss for 3 consecutive evaluations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/150, Loss: 1.6302253228646737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/150, Loss: 1.590943455696106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/150, Loss: 1.6209275170608803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/150, Loss: 1.6110777656237285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/150, Loss: 1.6127399184085704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 28.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/150, Loss: 1.6000090175204806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/150, Loss: 1.628499726454417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/150, Loss: 1.6112713791705944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/150, Loss: 1.5949715971946716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/150, Loss: 1.6350932805626481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69 Validation Loss: 1.4743273556232452, Validation Accuracy: 63.98\n",
      "No improvement in validation loss for 4 consecutive evaluations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/150, Loss: 1.582997041719931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/150, Loss: 1.622135058597282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 32.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/150, Loss: 1.6316734508231834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/150, Loss: 1.6050028249069497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:02<00:00, 26.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/150, Loss: 1.6178984001830772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/150, Loss: 1.5787855210127655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/150, Loss: 1.6051572804097776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 29.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/150, Loss: 1.6754335871449224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 30.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/150, Loss: 1.5827732174484819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:01<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/150, Loss: 1.638515869776408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 69.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79 Validation Loss: 1.3728472590446472, Validation Accuracy: 86.44\n",
      "No improvement in validation loss for 5 consecutive evaluations.\n",
      "Early stopping triggered.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, num_epochs=150, num_eval_epoch=10, patience = 5,optimizer=optimizer, scheduler=scheduler, save_dir=\"/home/blastaistudent/proj-pitch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM_Classifier(nn.Module):\n",
    "    def __init__(self, in_channels=8, hidden_dim=1024, num_classes=361, num_lstm_layers=2):\n",
    "        super(CNN_LSTM_Classifier, self).__init__()\n",
    "\n",
    "        self.cnn = CNN(in_channels=in_channels, hidden_dim=hidden_dim, num_bins=num_classes)\n",
    "        self.lstm = nn.LSTM(num_classes, hidden_dim, num_layers=num_lstm_layers, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim * 2, num_classes)  # *2 for bidirectional LSTM output\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B, C, T)\n",
    "        cnn_out = self.cnn(x)  # Output shape: (B, 1024, T)\n",
    "\n",
    "        # Permute to (B, T, 1024) for LSTM\n",
    "        lstm_input = cnn_out.permute(0, 2, 1)  # (B, T, 1024)\n",
    "\n",
    "        # LSTM output\n",
    "        lstm_out, _ = self.lstm(lstm_input)  # Shape: (B, T, hidden_dim * 2)\n",
    "\n",
    "        # Take the last time step's output for classification\n",
    "        lstm_out_last = lstm_out[:, -1, :]  # Shape: (B, hidden_dim * 2)\n",
    "\n",
    "        # Linear layer to get class scores\n",
    "        out = self.linear(lstm_out_last)  # Shape: (B, num_classes)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Layer (type:depth-idx)                   Param #\n",
      "=================================================================\n",
      "CNN_LSTM_Classifier                      --\n",
      "├─CNN: 1-1                               --\n",
      "│    └─Sequential: 2-1                   --\n",
      "│    │    └─ResBlock: 3-1                4,203,520\n",
      "│    │    └─ResBlock: 3-2                2,888,192\n",
      "│    │    └─ResBlock: 3-3                723,200\n",
      "│    │    └─ResBlock: 3-4                181,376\n",
      "│    │    └─ResBlock: 3-5                45,632\n",
      "│    │    └─ResBlock: 3-6                486,628\n",
      "├─LSTM: 1-2                              36,544,512\n",
      "├─Linear: 1-3                            739,689\n",
      "=================================================================\n",
      "Total params: 45,812,749\n",
      "Trainable params: 45,812,749\n",
      "Non-trainable params: 0\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "model = CNN_LSTM_Classifier(in_channels=256, hidden_dim=1024, num_classes=361, num_lstm_layers=2)\n",
    "print(summary(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]/tmp/ipykernel_2019828/3361870488.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  inputs = torch.tensor(inputs, dtype = torch.float)\n",
      "  0%|          | 0/54 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[269], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_eval_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/blastaistudent/proj-pitch/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[259], line 38\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, num_epochs, num_eval_epoch, patience, criterion, optimizer, scheduler, save_dir, gpu_number)\u001b[0m\n\u001b[1;32m     34\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     36\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[0;32m---> 38\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/modules/loss.py:1188\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1188\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1189\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1190\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/nn/functional.py:3104\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3103\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "train_model(model, train_dataloader, val_dataloader, num_epochs=150, num_eval_epoch=10, patience = 5,optimizer=optimizer, scheduler=scheduler, save_dir=\"/home/blastaistudent/proj-pitch/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pitch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
